{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91b5dbe-6054-4f15-90e7-65a192ab768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3001b6e3-35f5-4c73-a02f-70ed0566a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "MPS available:  True\n",
      "MPS is built:  True\n",
      "MPS is available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"MPS available: \", torch.mps.is_available())\n",
    "print(\"MPS is built: \", torch.backends.mps.is_built())\n",
    "print(\"MPS is available: \", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63918f2-69e3-4fa8-b3e6-acaa3f856abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe990b1-51ba-450f-a3b8-f9e2ad42163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e43ccd39-5c79-42ba-be09-36b798a3135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name is yolov8n.pt\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(f\"model name is {model.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3788ce6c-d3c6-4963-a434-6d8acbf5aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef57783-0719-4c39-ae68-f62f6ba34f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "response = requests.get(image_url)\n",
    "if response.status_code == 200:\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "else:\n",
    "    print(f\"failed to download image from {image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c27aa4-edb9-4acc-b4eb-fd4f9a60ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 1 stop sign, 33.1ms\n",
      "Speed: 4.7ms preprocess, 33.1ms inference, 20.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/Users/cwyark/project/snippets/my-ai-cookbooks/runs/detect/predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(source=img, device=device, imgsz=640, conf=0.25, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "784ebb5c-402c-4895-aaac-f15794425e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results are 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of results are {len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3212f4f-ccf1-4b50-9ff8-e891e2feee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[119, 146, 172],\n",
      "        [121, 148, 174],\n",
      "        [122, 152, 177],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[120, 147, 173],\n",
      "        [122, 149, 175],\n",
      "        [123, 153, 178],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[123, 150, 176],\n",
      "        [124, 151, 177],\n",
      "        [125, 155, 180],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[183, 182, 186],\n",
      "        [179, 178, 182],\n",
      "        [180, 179, 183],\n",
      "        ...,\n",
      "        [121, 111, 117],\n",
      "        [113, 103, 109],\n",
      "        [115, 105, 111]],\n",
      "\n",
      "       [[165, 164, 168],\n",
      "        [173, 172, 176],\n",
      "        [187, 186, 190],\n",
      "        ...,\n",
      "        [102,  92,  98],\n",
      "        [101,  91,  97],\n",
      "        [103,  93,  99]],\n",
      "\n",
      "       [[123, 122, 126],\n",
      "        [145, 144, 148],\n",
      "        [176, 175, 179],\n",
      "        ...,\n",
      "        [ 95,  85,  91],\n",
      "        [ 96,  86,  92],\n",
      "        [ 98,  88,  94]]], shape=(1080, 810, 3), dtype=uint8)\n",
      "orig_shape: (1080, 810)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/cwyark/project/snippets/my-ai-cookbooks/runs/detect/predict3'\n",
      "speed: {'preprocess': 4.688875007559545, 'inference': 33.07104199484456, 'postprocess': 20.800791011424735}\n"
     ]
    }
   ],
   "source": [
    "# get first result\n",
    "r = result[0]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74d0aa5-594e-4071-a4b6-0617673c9f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([ 5.,  0.,  0.,  0.,  0., 11.], device='mps:0')\n",
      "conf: tensor([0.8734, 0.8657, 0.8528, 0.8252, 0.2611, 0.2551], device='mps:0')\n",
      "data: tensor([[2.2871e+01, 2.3128e+02, 8.0500e+02, 7.5684e+02, 8.7345e-01, 5.0000e+00],\n",
      "        [4.8550e+01, 3.9855e+02, 2.4535e+02, 9.0270e+02, 8.6569e-01, 0.0000e+00],\n",
      "        [6.6947e+02, 3.9219e+02, 8.0972e+02, 8.7704e+02, 8.5284e-01, 0.0000e+00],\n",
      "        [2.2152e+02, 4.0580e+02, 3.4497e+02, 8.5754e+02, 8.2522e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5053e+02, 6.3007e+01, 8.7344e+02, 2.6111e-01, 0.0000e+00],\n",
      "        [5.8174e-02, 2.5446e+02, 3.2557e+01, 3.2487e+02, 2.5507e-01, 1.1000e+01]], device='mps:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([6, 6])\n",
      "xywh: tensor([[413.9369, 494.0588, 782.1313, 525.5630],\n",
      "        [146.9480, 650.6274, 196.7952, 504.1505],\n",
      "        [739.5964, 634.6108, 140.2471, 484.8493],\n",
      "        [283.2440, 631.6676, 123.4533, 451.7380],\n",
      "        [ 31.5035, 711.9840,  63.0070, 322.9179],\n",
      "        [ 16.3078, 289.6668,  32.4992,  70.4148]], device='mps:0')\n",
      "xywhn: tensor([[0.5110, 0.4575, 0.9656, 0.4866],\n",
      "        [0.1814, 0.6024, 0.2430, 0.4668],\n",
      "        [0.9131, 0.5876, 0.1731, 0.4489],\n",
      "        [0.3497, 0.5849, 0.1524, 0.4183],\n",
      "        [0.0389, 0.6592, 0.0778, 0.2990],\n",
      "        [0.0201, 0.2682, 0.0401, 0.0652]], device='mps:0')\n",
      "xyxy: tensor([[2.2871e+01, 2.3128e+02, 8.0500e+02, 7.5684e+02],\n",
      "        [4.8550e+01, 3.9855e+02, 2.4535e+02, 9.0270e+02],\n",
      "        [6.6947e+02, 3.9219e+02, 8.0972e+02, 8.7704e+02],\n",
      "        [2.2152e+02, 4.0580e+02, 3.4497e+02, 8.5754e+02],\n",
      "        [0.0000e+00, 5.5053e+02, 6.3007e+01, 8.7344e+02],\n",
      "        [5.8174e-02, 2.5446e+02, 3.2557e+01, 3.2487e+02]], device='mps:0')\n",
      "xyxyn: tensor([[2.8236e-02, 2.1415e-01, 9.9383e-01, 7.0078e-01],\n",
      "        [5.9939e-02, 3.6903e-01, 3.0290e-01, 8.3584e-01],\n",
      "        [8.2651e-01, 3.6314e-01, 9.9965e-01, 8.1207e-01],\n",
      "        [2.7348e-01, 3.7574e-01, 4.2589e-01, 7.9402e-01],\n",
      "        [0.0000e+00, 5.0975e-01, 7.7786e-02, 8.0874e-01],\n",
      "        [7.1820e-05, 2.3561e-01, 4.0194e-02, 3.0081e-01]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "boxes = r.boxes\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "232a392c-ad89-4710-9e45-a01cd43c1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = boxes.cls.tolist()\n",
    "conf = boxes.conf.tolist()\n",
    "xyxy = boxes.xyxy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "211d1d4c-44be-43ec-bade-103640e4e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Detections: {len(cls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "648607c5-6d42-4f81-a2fa-60ec6e78d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. bus  conf=0.87  box=[22.87126922607422, 231.27731323242188, 805.0025634765625, 756.84033203125]\n",
      "02. person  conf=0.87  box=[48.550418853759766, 398.55218505859375, 245.34556579589844, 902.7026977539062]\n",
      "03. person  conf=0.85  box=[669.472900390625, 392.1861572265625, 809.7200317382812, 877.0354614257812]\n",
      "04. person  conf=0.83  box=[221.517333984375, 405.798583984375, 344.9706726074219, 857.5365600585938]\n",
      "05. person  conf=0.26  box=[0.0, 550.5250244140625, 63.00697708129883, 873.4429321289062]\n",
      "06. stop sign  conf=0.26  box=[0.05817389488220215, 254.45938110351562, 32.557411193847656, 324.8741760253906]\n"
     ]
    }
   ],
   "source": [
    "for i, (c, cf, b) in enumerate(zip(cls, conf, xyxy), 1):\n",
    "    print(f\"{i:02d}. {model.model.names[int(c)]}  conf={cf:.2f}  box={b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14148414-c283-466a-9035-a5d982cb49ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
